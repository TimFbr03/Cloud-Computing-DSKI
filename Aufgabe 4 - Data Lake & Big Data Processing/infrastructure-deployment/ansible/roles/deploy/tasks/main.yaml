# main.yaml - Vollst√§ndig: App + Monitoring + Hadoop + Frontends

# ==========================
# Install prerequisites
# ==========================
- name: Install prerequisites
  apt:
    name:
      - curl
      - gnupg
      - lsb-release
      - python3-pip
    update_cache: yes
    state: present

- name: Install Kubernetes Python module
  pip:
    name: kubernetes
    executable: pip3

# ==========================
# k3s server installation
# ==========================
- name: Install k3s server
  shell: curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644
  args:
    creates: /usr/local/bin/k3s
  when: "'k3s_server' in group_names"

- name: Wait for k3s server to be ready
  shell: k3s kubectl get node
  register: k3s_status
  retries: 10
  delay: 30
  until: k3s_status.rc == 0
  when: "'k3s_server' in group_names"

- name: Save node token for agents
  command: cat /var/lib/rancher/k3s/server/node-token
  register: node_token
  when: "'k3s_server' in group_names"

- name: Copy token to localhost
  copy:
    content: "{{ node_token.stdout }}"
    dest: "./node-token"
    mode: '0600'
  delegate_to: localhost
  become: no
  when: "'k3s_server' in group_names"

# ==========================
# Helm installation
# ==========================
- name: Install Helm
  shell: curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
  args:
    creates: /usr/local/bin/helm
  when: "'k3s_server' in group_names"

# ==========================
# Copy Helm charts to server
# ==========================
- name: Copy Helm charts to server
  copy:
    src: "{{ playbook_dir }}/../helm/"
    dest: "/tmp/helm"
    mode: '0644'
    remote_src: no
    directory_mode: '0755'
  when: "'k3s_server' in group_names"

# ==========================
# Deploy App Chart (Original)
# ==========================
- name: Create namespace for app
  shell: kubectl create namespace microservices || true
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

- name: Deploy App Helm chart
  shell: |
    helm upgrade --install "{{ helm_release_name }}" "/tmp/helm/app" \
      --namespace microservices \
      --create-namespace \
      -f "/tmp/helm/app/values.yaml"
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  register: helm_app_result
  retries: 2
  delay: 10
  until: helm_app_result.rc == 0
  when: "'k3s_server' in group_names"

# ==========================
# Install Nginx Ingress Controller
# ==========================
- name: Install Nginx Ingress Controller
  shell: |
    kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

# ==========================
# Deploy Monitoring Stack
# ==========================
- name: Add Prometheus Helm repo
  shell: helm repo add prometheus-community https://prometheus-community.github.io/helm-charts && helm repo update
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

- name: Create monitoring namespace
  shell: kubectl create namespace monitoring || true
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

- name: Deploy kube-prometheus-stack
  shell: |
    helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \
      --namespace monitoring \
      --create-namespace \
      --set grafana.service.type=NodePort \
      --set grafana.service.nodePort=30090 \
      --set grafana.adminPassword=admin123
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  register: helm_monitoring_result
  retries: 2
  delay: 10
  until: helm_monitoring_result.rc == 0
  when: "'k3s_server' in group_names"

- name: Wait for Grafana pod to be ready
  shell: |
    kubectl -n monitoring wait --for=condition=Ready pod -l app.kubernetes.io/name=grafana,app.kubernetes.io/instance=monitoring --timeout=600s
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

# ==========================
# k3s agent installation
# ==========================
- name: Install k3s agent
  shell: |
    curl -sfL https://get.k3s.io | K3S_URL="https://{{ hostvars[groups['k3s_server'][0]].inventory_hostname }}:6443" \
    K3S_TOKEN="{{ lookup('file', './node-token') }}" sh -
  args:
    creates: /usr/local/bin/k3s
  when: "'k3s_agent' in group_names"

# ==========================
# Hadoop Data Lake Deployment (VEREINFACHT)
# ==========================
- name: Create Hadoop namespace
  shell: kubectl create namespace hadoop-cluster || true
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

- name: Deploy NameNode (simplified)
  shell: |
    cat << 'EOF' | kubectl apply -f -
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: hadoop-namenode
      namespace: hadoop-cluster
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: hadoop-namenode
      template:
        metadata:
          labels:
            app: hadoop-namenode
        spec:
          containers:
            - name: namenode
              image: apache/hadoop:3
              command: ["/bin/bash", "-c"]
              args:
                - |
                  if [ ! -d /tmp/hadoop-*/dfs/name/current ]; then
                    echo "Formatting NameNode..."
                    /opt/hadoop/bin/hdfs namenode -format -force -clusterId hadoop-cluster
                  fi
                  /opt/hadoop/bin/hdfs namenode
              ports:
                - containerPort: 9000
                  name: rpc
                - containerPort: 9870
                  name: http
              resources:
                requests:
                  memory: "1Gi"
                  cpu: "500m"
                limits:
                  memory: "2Gi"
                  cpu: "1000m"
              readinessProbe:
                httpGet:
                  path: /
                  port: 9870
                initialDelaySeconds: 60
                periodSeconds: 10
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: hadoop-namenode
      namespace: hadoop-cluster
    spec:
      selector:
        app: hadoop-namenode
      ports:
        - name: rpc
          port: 9000
          targetPort: 9000
        - name: http
          port: 9870
          targetPort: 9870
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: hadoop-namenode-web
      namespace: hadoop-cluster
    spec:
      type: NodePort
      selector:
        app: hadoop-namenode
      ports:
        - name: web
          port: 9870
          targetPort: 9870
          nodePort: 30091
    EOF
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

- name: Wait for NameNode to be ready
  shell: kubectl wait --for=condition=available deployment/hadoop-namenode -n hadoop-cluster --timeout=300s
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

- name: Deploy DataNodes (simplified)
  shell: |
    cat << 'EOF' | kubectl apply -f -
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: hadoop-datanode
      namespace: hadoop-cluster
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: hadoop-datanode
      template:
        metadata:
          labels:
            app: hadoop-datanode
        spec:
          containers:
            - name: datanode
              image: apache/hadoop:3
              command: ["/bin/bash", "-c"]
              args:
                - |
                  echo "Waiting for NameNode..."
                  until nc -z hadoop-namenode 9000; do
                    echo "NameNode not ready, waiting..."
                    sleep 5
                  done
                  echo "Starting DataNode..."
                  /opt/hadoop/bin/hdfs datanode
              ports:
                - containerPort: 9864
                  name: http
                - containerPort: 9866
                  name: data
              resources:
                requests:
                  memory: "1Gi"
                  cpu: "500m"
                limits:
                  memory: "2Gi"
                  cpu: "1000m"
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: hadoop-datanode
      namespace: hadoop-cluster
    spec:
      selector:
        app: hadoop-datanode
      ports:
        - name: http
          port: 9864
          targetPort: 9864
        - name: data
          port: 9866
          targetPort: 9866
    EOF
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

- name: Wait for DataNodes to be ready
  shell: kubectl wait --for=condition=available deployment/hadoop-datanode -n hadoop-cluster --timeout=300s
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

# ==========================
# Deploy YARN ResourceManager
# ==========================
- name: Deploy YARN ResourceManager
  shell: |
    cat << 'EOF' | kubectl apply -f -
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: hadoop-resourcemanager
      namespace: hadoop-cluster
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: hadoop-resourcemanager
      template:
        metadata:
          labels:
            app: hadoop-resourcemanager
        spec:
          containers:
            - name: resourcemanager
              image: apache/hadoop:3
              command: ["/bin/bash", "-c"]
              args:
                - |
                  echo "Waiting for NameNode..."
                  until nc -z hadoop-namenode 9000; do
                    sleep 5
                  done
                  echo "Starting ResourceManager..."
                  /opt/hadoop/bin/yarn resourcemanager
              ports:
                - containerPort: 8088
                  name: web
                - containerPort: 8030
                - containerPort: 8031
                - containerPort: 8032
                - containerPort: 8033
              resources:
                requests:
                  memory: "1Gi"
                  cpu: "500m"
                limits:
                  memory: "2Gi"
                  cpu: "1000m"
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: hadoop-resourcemanager
      namespace: hadoop-cluster
    spec:
      selector:
        app: hadoop-resourcemanager
      ports:
        - name: web
          port: 8088
          targetPort: 8088
        - name: scheduler
          port: 8030
          targetPort: 8030
        - name: tracker
          port: 8031
          targetPort: 8031
        - name: resource-tracker
          port: 8032
          targetPort: 8032
        - name: admin
          port: 8033
          targetPort: 8033
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: hadoop-resourcemanager-web
      namespace: hadoop-cluster
    spec:
      type: NodePort
      selector:
        app: hadoop-resourcemanager
      ports:
        - name: web
          port: 8088
          targetPort: 8088
          nodePort: 30092
    EOF
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

# ==========================
# Deploy HUE (Hadoop User Experience) - Web Frontend
# ==========================
- name: Deploy HUE (Hadoop Web Frontend)
  shell: |
    cat << 'EOF' | kubectl apply -f -
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: hue
      namespace: hadoop-cluster
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: hue
      template:
        metadata:
          labels:
            app: hue
        spec:
          containers:
            - name: hue
              image: gethue/hue:latest
              ports:
                - containerPort: 8888
                  name: web
              env:
                - name: HUE_CONF_DIR
                  value: "/usr/share/hue/desktop/conf"
              resources:
                requests:
                  memory: "512Mi"
                  cpu: "250m"
                limits:
                  memory: "1Gi"
                  cpu: "500m"
              readinessProbe:
                httpGet:
                  path: /
                  port: 8888
                initialDelaySeconds: 30
                periodSeconds: 10
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: hue-web
      namespace: hadoop-cluster
    spec:
      type: NodePort
      selector:
        app: hue
      ports:
        - name: web
          port: 8888
          targetPort: 8888
          nodePort: 30094
    EOF
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

# ==========================
# Deploy Hadoop File Browser (Alternative Frontend)
# ==========================
- name: Deploy Simple Hadoop File Browser
  shell: |
    cat << 'EOF' | kubectl apply -f -
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: hdfs-browser
      namespace: hadoop-cluster
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: hdfs-browser
      template:
        metadata:
          labels:
            app: hdfs-browser
        spec:
          containers:
            - name: hdfs-browser
              image: nginx:alpine
              ports:
                - containerPort: 80
              volumeMounts:
                - name: hdfs-browser-config
                  mountPath: /usr/share/nginx/html
              resources:
                requests:
                  memory: "128Mi"
                  cpu: "100m"
                limits:
                  memory: "256Mi"
                  cpu: "200m"
          volumes:
            - name: hdfs-browser-config
              configMap:
                name: hdfs-browser-config
    ---
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: hdfs-browser-config
      namespace: hadoop-cluster
    data:
      index.html: |
        <!DOCTYPE html>
        <html>
        <head>
            <title>Hadoop Data Lake Dashboard</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }
                .container { max-width: 1200px; margin: 0 auto; }
                .card { background: white; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
                .links { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
                .link-card { background: #2196F3; color: white; padding: 20px; text-decoration: none; border-radius: 8px; display: block; transition: background 0.3s; }
                .link-card:hover { background: #1976D2; color: white; text-decoration: none; }
                h1 { color: #333; text-align: center; }
                h2 { color: #666; }
                .status { padding: 10px; background: #e8f5e8; border-left: 4px solid #4caf50; margin: 10px 0; }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>üêò Hadoop Data Lake Dashboard</h1>
                
                <div class="card">
                    <div class="status">
                        ‚úÖ Hadoop Cluster is running with simplified configuration
                    </div>
                </div>
                
                <div class="card">
                    <h2>üîß Hadoop Services</h2>
                    <div class="links">
                        <a href="http://REPLACE_WITH_NODE_IP:30091" class="link-card" target="_blank">
                            <h3>üìÅ HDFS NameNode</h3>
                            <p>Browse HDFS file system, check cluster status</p>
                        </a>
                        <a href="http://REPLACE_WITH_NODE_IP:30092" class="link-card" target="_blank">
                            <h3>‚öôÔ∏è YARN ResourceManager</h3>
                            <p>Monitor applications and resource allocation</p>
                        </a>
                        <a href="http://REPLACE_WITH_NODE_IP:30094" class="link-card" target="_blank">
                            <h3>üé® HUE Web Interface</h3>
                            <p>User-friendly Hadoop web interface</p>
                        </a>
                    </div>
                </div>
                
                <div class="card">
                    <h2>üìä Monitoring</h2>
                    <div class="links">
                        <a href="http://REPLACE_WITH_NODE_IP:30090" class="link-card" target="_blank">
                            <h3>üìà Grafana Dashboard</h3>
                            <p>Cluster monitoring and metrics (admin/admin123)</p>
                        </a>
                    </div>
                </div>
                
                <div class="card">
                    <h2>üß™ Quick Commands</h2>
                    <pre style="background: #f0f0f0; padding: 15px; border-radius: 4px;">
    # Check cluster status
    kubectl get pods -n hadoop-cluster
    
    # Test HDFS
    kubectl exec -n hadoop-cluster deployment/hadoop-namenode -- /opt/hadoop/bin/hdfs dfs -ls /
    
    # Create test directory
    kubectl exec -n hadoop-cluster deployment/hadoop-namenode -- /opt/hadoop/bin/hdfs dfs -mkdir /test
                    </pre>
                </div>
            </div>
        </body>
        </html>
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: hdfs-browser-web
      namespace: hadoop-cluster
    spec:
      type: NodePort
      selector:
        app: hdfs-browser
      ports:
        - name: web
          port: 80
          targetPort: 80
          nodePort: 30095
    EOF
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"

# ==========================
# Create sample data and test HDFS
# ==========================
- name: Create sample data directory
  file:
    path: /tmp/hadoop-data
    state: directory
    mode: '0755'
  when: "'k3s_server' in group_names"

- name: Copy real datasets to server
  copy:
    src: "{{ playbook_dir }}/../../data/"
    dest: "/tmp/hadoop-data/"
    mode: '0644'
  when: "'k3s_server' in group_names"
  ignore_errors: yes

- name: Upload datasets to HDFS
  shell: |
    # Wait for HDFS to be ready
    sleep 60
    
    # Create HDFS structure and upload data
    kubectl exec -n hadoop-cluster deployment/hadoop-namenode -- /opt/hadoop/bin/hdfs dfs -mkdir -p /datalake/datasets || true
    kubectl exec -n hadoop-cluster deployment/hadoop-namenode -- /opt/hadoop/bin/hdfs dfs -mkdir -p /datalake/schemas || true
    
    # Copy files to namenode pod and then to HDFS
    for file in /tmp/hadoop-data/*.json; do
      if [ -f "$file" ]; then
        filename=$(basename "$file")
        kubectl cp "$file" hadoop-cluster/$(kubectl get pod -n hadoop-cluster -l app=hadoop-namenode -o jsonpath='{.items[0].metadata.name}'):/tmp/"$filename"
        kubectl exec -n hadoop-cluster deployment/hadoop-namenode -- /opt/hadoop/bin/hdfs dfs -put /tmp/"$filename" /datalake/datasets/ || echo "File $filename might already exist"
      fi
    done
    
    echo "Data upload completed"
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"
  ignore_errors: yes

# ==========================
# Final status and summary
# ==========================
- name: Update dashboard with real IP
  shell: |
    # Update the dashboard with real node IP
    kubectl patch configmap hdfs-browser-config -n hadoop-cluster --type merge -p '{"data":{"index.html":"'$(kubectl get configmap hdfs-browser-config -n hadoop-cluster -o jsonpath='{.data.index\.html}' | sed "s/REPLACE_WITH_NODE_IP/{{ ansible_default_ipv4.address }}/g")'"}}' || true
    
    # Restart the dashboard to pick up changes
    kubectl rollout restart deployment/hdfs-browser -n hadoop-cluster || true
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  when: "'k3s_server' in group_names"
  ignore_errors: yes

- name: Display comprehensive deployment summary
  debug:
    msg: |
      ============================================
      üéâ COMPLETE DEPLOYMENT SUCCESSFUL! üéâ
      ============================================
      
      üì± YOUR APPLICATIONS:
      - Todo App (Frontend/Backend): Available via Ingress
      - Database: Internal PostgreSQL service
      
      üìä MONITORING:
      - Grafana: http://{{ ansible_default_ipv4.address }}:30090 (admin/admin123)
      
      üêò HADOOP DATA LAKE:
      - NameNode Web UI: http://{{ ansible_default_ipv4.address }}:30091
      - YARN ResourceManager: http://{{ ansible_default_ipv4.address }}:30092
      - HUE Web Interface: http://{{ ansible_default_ipv4.address }}:30094
      - Dashboard: http://{{ ansible_default_ipv4.address }}:30095
      
      üîß QUICK COMMANDS:
      1. Check all pods: kubectl get pods --all-namespaces
      2. Test HDFS: kubectl exec -n hadoop-cluster deployment/hadoop-namenode -- /opt/hadoop/bin/hdfs dfs -ls /datalake
      3. Check logs: kubectl logs -n hadoop-cluster deployment/hadoop-namenode
      
      üìÅ DATA:
      Your datasets should be available at /datalake/datasets/ in HDFS
      
      ‚ö†Ô∏è  Note: Using ephemeral storage - data survives container restarts but not pod recreation
  when: "'k3s_server' in group_names"
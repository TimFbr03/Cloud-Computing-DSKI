# Hinzuf端gung zu spark-job.yaml - Spark History Server mit NodePort
---
# Service f端r Spark History Server (mit NodePort f端r externen Zugriff)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-history-server
  namespace: hadoop-cluster
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-history-server
  template:
    metadata:
      labels:
        app: spark-history-server
    spec:
      containers:
        - name: spark-history-server
          image: bitnami/spark:3.4
          command: ["/opt/bitnami/spark/bin/spark-class"]
          args: ["org.apache.spark.deploy.history.HistoryServer"]
          ports:
            - containerPort: 18080
          env:
            - name: SPARK_HISTORY_OPTS
              value: "-Dspark.history.fs.logDirectory=hdfs://hadoop-namenode:9000/spark-logs"
          volumeMounts:
            - name: hadoop-config
              mountPath: /opt/hadoop/etc/hadoop
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
      volumes:
        - name: hadoop-config
          configMap:
            name: hadoop-config

---
# Interner ClusterIP Service
apiVersion: v1
kind: Service
metadata:
  name: spark-history-server
  namespace: hadoop-cluster
spec:
  type: ClusterIP
  selector:
    app: spark-history-server
  ports:
    - name: web
      port: 18080
      targetPort: 18080

---
# Externer NodePort Service (f端r Web-UI Zugriff)
apiVersion: v1
kind: Service
metadata:
  name: spark-history-server-web
  namespace: hadoop-cluster
  labels:
    app: spark-history-server
    service-type: web-ui
spec:
  type: NodePort
  selector:
    app: spark-history-server
  ports:
    - name: spark-history-web
      port: 18080
      targetPort: 18080
      nodePort: 30093
      protocol: TCP